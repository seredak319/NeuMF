{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ac635b-7fe0-49ad-afec-b2d3cc6ffb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import sparse\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b247bb-f328-4fee-800d-4d7262ed16f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.0\n",
      "Pandas version: 2.0.3\n",
      "Numpy version: 1.23.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c68374-c028-495f-80ba-341edee044d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wgrano dane do pamięci\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('data/full_ratings.csv', low_memory=False)\n",
    "print(\"Wgrano dane do pamięci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a149b6d-d110-44bb-955a-1b5b6ee1aeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534782</th>\n",
       "      <td>670</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534783</th>\n",
       "      <td>670</td>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534784</th>\n",
       "      <td>670</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534785</th>\n",
       "      <td>670</td>\n",
       "      <td>795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534786</th>\n",
       "      <td>670</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534787 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            0        0       1\n",
       "1            0        1       1\n",
       "2            0        2       1\n",
       "3            0        3       1\n",
       "4            0        4       0\n",
       "...        ...      ...     ...\n",
       "534782     670      792       0\n",
       "534783     670      793       0\n",
       "534784     670      794       0\n",
       "534785     670      795       0\n",
       "534786     670      796       0\n",
       "\n",
       "[534787 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8969970a-3158-47ab-a2f5-431baaa48d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users:  671\n",
      "number of unique items:  797\n"
     ]
    }
   ],
   "source": [
    "n_users = len(ratings['userId'].unique())\n",
    "n_items = len(ratings['movieId'].unique())\n",
    "print(\"number of unique users: \", n_users)\n",
    "print(\"number of unique items: \", n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dfa7bfd-2a20-4e57-bf6c-2482e4de24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Flatten, Dot, Add\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "def create_mf_model(num_users, num_items, embedding_size, learning_rate):\n",
    "    # Wejścia dla użytkowników i filmów\n",
    "    user_input = Input(shape=(1,), name='userId')\n",
    "    item_input = Input(shape=(1,), name='movieId')\n",
    "\n",
    "    # Warstwa osadzania dla użytkowników i filmów\n",
    "    user_embedding = Embedding(num_users, embedding_size, embeddings_initializer='he_normal', name='user_embedding')(user_input)\n",
    "    item_embedding = Embedding(num_items, embedding_size, embeddings_initializer='he_normal', name='item_embedding')(item_input)\n",
    "\n",
    "\n",
    "    # Spłaszczenie wektorów osadzania\n",
    "    user_vec = Flatten()(user_embedding)\n",
    "    item_vec = Flatten()(item_embedding)\n",
    "\n",
    "    # Obliczenie iloczynu skalarnego wektorów użytkowników i filmów\n",
    "    dot_user_item = Dot(axes=1)([user_vec, item_vec])\n",
    "\n",
    "    # Warstwa osadzania dla biasów użytkowników i filmów\n",
    "    user_bias = Embedding(num_users, 1, name='user_bias')(user_input)\n",
    "    item_bias = Embedding(num_items, 1, name='item_bias')(item_input)\n",
    "\n",
    "    # Spłaszczenie wektorów biasów\n",
    "    user_bias = Flatten()(user_bias)\n",
    "    item_bias = Flatten()(item_bias)\n",
    "\n",
    "    # Dodanie iloczynu skalarnego do biasów użytkowników i filmów\n",
    "    add_bias = Add()([dot_user_item, user_bias, item_bias])\n",
    "\n",
    "    # Zbudowanie modelu\n",
    "    mf_model = Model(inputs=[user_input, item_input], outputs=add_bias)\n",
    "    \n",
    "    # Ustawienie optymalizatora z określonym współczynnikiem uczenia\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    mf_model.compile(optimizer=optimizer, \n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=[\n",
    "                         tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "                         tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "                         tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "                         tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "                         tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "                         tf.keras.metrics.Precision(name=\"precision\"),\n",
    "                         tf.keras.metrics.Recall(name=\"recall\"),\n",
    "                         tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                     ])\n",
    "    return mf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6d2ff-bbae-4603-bcde-ffa48d4ad1c0",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07ad2d51-b7db-4477-b312-51ab88a33783",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 4\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size=16\n",
    "val_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94511095-87a6-47f4-8d1e-13ac022ea100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(data: pd.DataFrame, target: str, batch_size: int = 128, val_split: float = 0.2):\n",
    "    # Convert the DataFrame to TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "        'userId': data['userId'].values,\n",
    "        'movieId': data['movieId'].values\n",
    "    }, data[target].values))\n",
    "    \n",
    "    # Shuffle and split the dataset\n",
    "    dataset = dataset.shuffle(buffer_size=len(data))\n",
    "    train_size = int((1 - val_split) * len(data))\n",
    "    \n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    \n",
    "    # Batch the datasets\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "m_train, m_val = make_tf_dataset(ratings, [\"rating\"], batch_size, val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fa143fd-1bf9-4134-b9ee-393b82b690ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba elementów w ds_train: 26740\n",
      "Liczba elementów w ds_val: 6685\n"
     ]
    }
   ],
   "source": [
    "num_elements = tf.data.experimental.cardinality(m_train).numpy()\n",
    "print(f\"Liczba elementów w ds_train: {num_elements}\")\n",
    "num_elements_val = tf.data.experimental.cardinality(m_val).numpy()\n",
    "print(f\"Liczba elementów w ds_val: {num_elements_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0333eb2a-1835-4da9-a0aa-aad81cf40efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Epoch 1/10\n",
      "26740/26740 [==============================] - 36s 1ms/step - loss: 0.0576 - tp: 2015.0000 - fp: 864.0000 - tn: 395882.0000 - fn: 29068.0000 - accuracy: 0.9300 - precision: 0.6999 - recall: 0.0648 - auc: 0.8047 - val_loss: 0.0519 - val_tp: 1230.0000 - val_fp: 535.0000 - val_tn: 98717.0000 - val_fn: 6476.0000 - val_accuracy: 0.9345 - val_precision: 0.6969 - val_recall: 0.1596 - val_auc: 0.8565\n",
      "Epoch 2/10\n",
      "26740/26740 [==============================] - 35s 1ms/step - loss: 0.0527 - tp: 5565.0000 - fp: 2669.0000 - tn: 394076.0000 - fn: 25519.0000 - accuracy: 0.9341 - precision: 0.6759 - recall: 0.1790 - auc: 0.8503 - val_loss: 0.0504 - val_tp: 1486.0000 - val_fp: 631.0000 - val_tn: 98680.0000 - val_fn: 6161.0000 - val_accuracy: 0.9365 - val_precision: 0.7019 - val_recall: 0.1943 - val_auc: 0.8612\n",
      "Epoch 3/10\n",
      "26740/26740 [==============================] - 34s 1ms/step - loss: 0.0522 - tp: 6161.0000 - fp: 2858.0000 - tn: 393725.0000 - fn: 25085.0000 - accuracy: 0.9347 - precision: 0.6831 - recall: 0.1972 - auc: 0.8555 - val_loss: 0.0503 - val_tp: 1711.0000 - val_fp: 629.0000 - val_tn: 98553.0000 - val_fn: 6065.0000 - val_accuracy: 0.9374 - val_precision: 0.7312 - val_recall: 0.2200 - val_auc: 0.8652\n",
      "Epoch 4/10\n",
      "26740/26740 [==============================] - 34s 1ms/step - loss: 0.0521 - tp: 6449.0000 - fp: 2871.0000 - tn: 393664.0000 - fn: 24845.0000 - accuracy: 0.9352 - precision: 0.6920 - recall: 0.2061 - auc: 0.8566 - val_loss: 0.0512 - val_tp: 1685.0000 - val_fp: 700.0000 - val_tn: 98408.0000 - val_fn: 6165.0000 - val_accuracy: 0.9358 - val_precision: 0.7065 - val_recall: 0.2146 - val_auc: 0.8651\n",
      "Epoch 5/10\n",
      "26740/26740 [==============================] - 34s 1ms/step - loss: 0.0522 - tp: 6519.0000 - fp: 2924.0000 - tn: 393649.0000 - fn: 24737.0000 - accuracy: 0.9353 - precision: 0.6904 - recall: 0.2086 - auc: 0.8546 - val_loss: 0.0508 - val_tp: 1639.0000 - val_fp: 681.0000 - val_tn: 98549.0000 - val_fn: 6089.0000 - val_accuracy: 0.9367 - val_precision: 0.7065 - val_recall: 0.2121 - val_auc: 0.8640\n",
      "6685/6685 [==============================] - 8s 996us/step - loss: 0.0510 - tp: 1698.0000 - fp: 674.0000 - tn: 98445.0000 - fn: 6141.0000 - accuracy: 0.9363 - precision: 0.7159 - recall: 0.2166 - auc: 0.8653\n",
      "Matrix Factorization Model Evaluation: [0.05102419853210449, 1698.0, 674.0, 98445.0, 6141.0, 0.9362834095954895, 0.7158516049385071, 0.21660925447940826, 0.8653073906898499]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "mf_model = create_mf_model(n_users, n_items, embedding_size, learning_rate)\n",
    "\n",
    "# Definiowanie logów i callbacków\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "\n",
    "# Trening modelu\n",
    "history = mf_model.fit(\n",
    "    m_train,\n",
    "    validation_data=m_val,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Ewaluacja modelu\n",
    "evaluation = mf_model.evaluate(m_val)\n",
    "print(f'Matrix Factorization Model Evaluation: {evaluation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fe71df0-9fa8-4ec0-98fa-45460a447972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "mf_model.save('models/MF_model.h5')\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd81f8-2668-49c4-a596-3e06a10b2edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b6f59-8fbd-4ab4-b830-ae1cd4578183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu_env)",
   "language": "python",
   "name": "tf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
